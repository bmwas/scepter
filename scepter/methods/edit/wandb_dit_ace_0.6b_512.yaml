ENV:
  BACKEND: nccl
  SEED: 2024
#
SOLVER:
  NAME: ACESolver
  RESUME_FROM:
  LOAD_MODEL_ONLY: True
  USE_FSDP: False
  SHARDING_STRATEGY:
  USE_AMP: True
  DTYPE: float16
  CHANNELS_LAST: True
  MAX_STEPS: 200
  MAX_EPOCHS: -1
  NUM_FOLDS: 10
  ACCU_STEP: 1
  EVAL_INTERVAL: 10
  RESCALE_LR: False
  #
  WORK_DIR: ./cache/save_data/ace_0.6b_512
  LOG_FILE: std_log.txt
  #
  FILE_SYSTEM:
    - NAME: "HuggingfaceFs"
      TEMP_DIR: ./cache/cache_data
    - NAME: "LocalFs"
      TEMP_DIR: ./cache/cache_data
    - NAME: "ModelscopeFs"
      TEMP_DIR: ./cache/cache_data

  #
  MODEL:
    NAME: LatentDiffusionACE
    PRETRAINED_MODEL:
    IGNORE_KEYS: [ ]
    SCALE_FACTOR: 0.18215
    SIZE_FACTOR: 8
    DECODER_BIAS: 0.5
    DEFAULT_N_PROMPT:
    USE_EMA: True
    EMA_DECAY: 0.9999
    EVAL_EMA: True
    USE_SWA: True  # Enable Stochastic Weight Averaging for extreme stability
    SWA_START: 100  # Start SWA after 100 steps
    SWA_FREQ: 10    # Average weights every 10 steps
    TEXT_IDENTIFIER: [ '{image}', '{image1}', '{image2}', '{image3}', '{image4}', '{image5}', '{image6}', '{image7}', '{image8}', '{image9}' ]
    USE_TEXT_POS_EMBEDDINGS: True
    TUNER:
      NAME: SwiftLoRA
      R: 64
      LORA_ALPHA: 64
      LORA_DROPOUT: 0.0
      BIAS: "none"
      TARGET_MODULES:
        - "attn.q"
        - "attn.k"
        - "attn.v"
        - "attn.o"
        - "cross_attn.q"
        - "cross_attn.k"
        - "cross_attn.v"
        - "cross_attn.o"
    #
    DIFFUSION:
      NAME: BaseDiffusion
      PREDICTION_TYPE: eps
      MIN_SNR_GAMMA: 5.0  # Add SNR clamping for better stability
      NOISE_SCHEDULER:
        NAME: LinearScheduler
        NUM_TIMESTEPS: 1000
        BETA_MIN: 0.0001
        BETA_MAX: 0.02
    #
    DIFFUSION_MODEL:
      NAME: ACE
      PRETRAINED_MODEL: hf://scepter-studio/ACE-0.6B-512px@models/dit/ace_0.6b_512px.pth
      IGNORE_KEYS: [ ]
      PATCH_SIZE: 2
      IN_CHANNELS: 4
      HIDDEN_SIZE: 1152
      DEPTH: 28
      NUM_HEADS: 16
      MLP_RATIO: 4.0
      PRED_SIGMA: True
      DROP_PATH: 0.0
      WINDOW_DIZE: 0
      Y_CHANNELS: 4096
      MAX_SEQ_LEN: 1024
      QK_NORM: True
      USE_GRAD_CHECKPOINT: True
      ATTENTION_BACKEND: flash_attn
    #
    FIRST_STAGE_MODEL:
      NAME: AutoencoderKL
      EMBED_DIM: 4
      PRETRAINED_MODEL: hf://scepter-studio/ACE-0.6B-512px@models/vae/vae.bin
      IGNORE_KEYS: []
      #
      ENCODER:
        NAME: Encoder
        CH: 128
        OUT_CH: 3
        NUM_RES_BLOCKS: 2
        IN_CHANNELS: 3
        ATTN_RESOLUTIONS: [ ]
        CH_MULT: [ 1, 2, 4, 4 ]
        Z_CHANNELS: 4
        DOUBLE_Z: True
        DROPOUT: 0.0
        RESAMP_WITH_CONV: True
      #
      DECODER:
        NAME: Decoder
        CH: 128
        OUT_CH: 3
        NUM_RES_BLOCKS: 2
        IN_CHANNELS: 3
        ATTN_RESOLUTIONS: [ ]
        CH_MULT: [ 1, 2, 4, 4 ]
        Z_CHANNELS: 4
        DROPOUT: 0.0
        RESAMP_WITH_CONV: True
        GIVE_PRE_END: False
        TANH_OUT: False
    #
    COND_STAGE_MODEL:
      NAME: T5EmbedderHF
      PRETRAINED_MODEL: hf://scepter-studio/ACE-0.6B-512px@models/text_encoder/t5-v1_1-xxl/
      TOKENIZER_PATH: hf://scepter-studio/ACE-0.6B-512px@models/tokenizer/t5-v1_1-xxl
      LENGTH: 120
      T5_DTYPE: bfloat16
      ADDED_IDENTIFIER: [ '{image}', '{caption}', '{mask}', '{ref_image}', '{image1}', '{image2}', '{image3}', '{image4}', '{image5}', '{image6}', '{image7}', '{image8}', '{image9}' ]
      CLEAN: whitespace
      USE_GRAD: False
    LOSS:
      NAME: ReconstructLoss
      LOSS_TYPE: l2
      LOSS_WEIGHT: 1.0
      LOSS_CLIP: 10.0
  #
  SAMPLE_ARGS:
    SAMPLER: ddim
    SAMPLE_STEPS: 20
    GUIDE_SCALE: 4.5
    GUIDE_RESCALE: 0.5
  #
  OPTIMIZER:
    NAME: AdamW
    LEARNING_RATE: 1e-5  # Increased from 1e-8
    EPS: 1e-6
    WEIGHT_DECAY: 1e-5
    CLIP_GRAD_NORM: 0.5 # increased from 0.1
    BETAS: [0.9, 0.999]
    GRAD_ACCUMULATION: 4

  LR_SCHEDULER:
    NAME: CosineAnnealingLR
    T_MAX: 1000  # Adjust to match MAX_STEPS
    ETA_MIN: 1e-7  # Small non-zero minimum LR for stability
    WARMUP_STEPS: 300  # Increased warm-up for smoother convergence

  #
  TRAIN_DATA:
    NAME: CSVInRAMDataset
    MODE: train
    CSV_PATH: ./cache/datasets/therapy_pair/images_therapist/training.csv
    IMAGE_ROOT_DIR: ./cache/datasets/therapy_pair
    BATCH_SIZE: 4
    NUM_WORKERS: 1
    SAMPLER:
      NAME: LoopSampler
      SHUFFLE: false
    DROP_LAST: false
  #
  VAL_DATA:
    NAME: CSVInRAMDataset
    MODE: validation
    CSV_PATH: ./cache/datasets/therapy_pair/images_therapist/validation.csv
    IMAGE_ROOT_DIR: ./cache/datasets/therapy_pair
    BATCH_SIZE: 1
    NUM_WORKERS: 1
    DROP_LAST: false
  #
  TRAIN_HOOKS:
    # ---------------- core training ----------------
    - {NAME: BackwardHook,   PRIORITY: 0}
    - {NAME: LogHook,        LOG_INTERVAL: 50, PRIORITY: 100}

    # ---------------- checkpoints & metrics ----------------
    - {NAME: CheckpointHook, INTERVAL: 500, PRIORITY: 300,
      MAX_TO_KEEP: 2,
      PUSH_TO_HUB: false,
      HUB_MODEL_ID: "Benson/ace-model-0.6b-512",
      HUB_PRIVATE: false,
      SAVE_LORA: true,
      HUB_TOKEN: "${env:HUGGINGFACE_TOKEN}"}
      
    # ---------------- Complete model with all components ----------------
    - {NAME: FinalModelHFHook, PRIORITY: 1200,
      OUTPUT_DIR: "FINAL_MODEL_HF",
      SAVE_ON_STEPS: [200],  # Save at these specific steps
      MODEL_COMPONENTS: ["dit", "text_encoder", "tokenizer", "vae"],
      PUSH_TO_HUB: true,
      HUB_MODEL_ID: "Benson/ace-model-0.6b-512-complete",
      HUB_PRIVATE: false,
      HUB_TOKEN: "${env:HUGGINGFACE_TOKEN}"}
      
    # ---------------- LoRA model saving hook using standard hook ----------------
    - {NAME: FinalModelHFHook, PRIORITY: 1100,
      OUTPUT_DIR: "FINAL_LORA_HF",
      SAVE_ON_STEPS: [200],
      SAVE_LORA_ONLY: true,
      MODEL_COMPONENTS: ["lora_adapters"],  # Only save LoRA adapter weights
      PUSH_TO_HUB: true,
      HUB_MODEL_ID: "Benson/ace-model-0.6b-512-lora-final",
      HUB_PRIVATE: false,
      HUB_TOKEN: "${env:HUGGINGFACE_TOKEN}"}
      
    # ---------------- LoRA visualization hook ----------------
    - {NAME: LoRAWandbVizHook, PRIORITY: 500,
      VIZ_INTERVAL: 50,         # Generate images every 50 steps
      VIZ_START: 5,             # Start at step 5
      NUM_VAL_SAMPLES: 3,       # Number of validation samples to use
      NUM_INFERENCE_STEPS: 20,  # Faster sampling for visualization
      GUIDANCE_SCALE: 4.5,      # Standard guidance scale
      IMAGE_SIZE: 512,
      LOG_PROMPTS: true,        # Log the prompts used for visualization
      }
      
    # ---------------- File tracking and documentation ----------------
    - {NAME: WandbFileTrackerHook, PRIORITY: 400,
      TRACK_INTERVAL: 300,     # Check for new files every 5 minutes
      WATCHED_DIRECTORIES: [
        "./cache/save_data",   # Main save directory
        "./cache/datasets/therapy_pair/images_therapist",  # CSV files directory
      ],
      SPECIFIC_FILES: [
        "./scepter/methods/edit/wandb_dit_ace_0.6b_512.yaml"  # Configuration file
      ],
      FILE_EXTENSIONS: [
        ".csv", ".yaml", ".yml", ".json", ".txt",  # Data and config files
        ".pth", ".bin", ".pt",                    # Model weights
        ".png", ".jpg", ".jpeg"                   # Generated images
      ],
      CREATE_RESULTS_ARTIFACT: true,
      ARTIFACT_NAME: "training_files",
      ARTIFACT_TYPE: "dataset",
      ARTIFACT_DESCRIPTION: "Training configuration and dataset files"}
      
    # ---------------- images / probe data -----------------
    - {NAME: ProbeDataHook,       PROB_INTERVAL: 100}                        # keeps local saves
